{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4TowTDflDs5C"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# lab1_tools.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# - Functions given by the exercise --------------------------------------------\n",
    "\n",
    "def tidigit2labels(tidigitsarray):\n",
    "    \"\"\"\n",
    "    Return a list of labels including gender, speaker, digit and repetition information for each\n",
    "    utterance in tidigitsarray. Useful for plots.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    nex = len(tidigitsarray)\n",
    "    for ex in range(nex):\n",
    "        labels.append(tidigitsarray[ex]['gender'] + '_' + \n",
    "                      tidigitsarray[ex]['speaker'] + '_' + \n",
    "                      tidigitsarray[ex]['digit'] + '_' + \n",
    "                      tidigitsarray[ex]['repetition'])\n",
    "    return labels\n",
    "\n",
    "\n",
    "def dither(samples, level=1.0):\n",
    "    \"\"\"\n",
    "    Applies dithering to the samples. Adds Gaussian noise to the samples to avoid numerical\n",
    "        errors in the subsequent FFT calculations.\n",
    "\n",
    "        samples: array of speech samples\n",
    "        level: decides the amount of dithering (see code for details)\n",
    "\n",
    "    Returns:\n",
    "        array of dithered samples (same shape as samples)\n",
    "    \"\"\"\n",
    "    return samples + level*np.random.normal(0,1, samples.shape)\n",
    "    \n",
    "\n",
    "def lifter(mfcc, lifter=22):\n",
    "    \"\"\"\n",
    "    Applies liftering to improve the relative range of MFCC coefficients.\n",
    "\n",
    "       mfcc: NxM matrix where N is the number of frames and M the number of MFCC coefficients\n",
    "       lifter: lifering coefficient\n",
    "\n",
    "    Returns:\n",
    "       NxM array with lifeterd coefficients\n",
    "    \"\"\"\n",
    "    nframes, nceps = mfcc.shape\n",
    "    cepwin = 1.0 + lifter/2.0 * np.sin(np.pi * np.arange(nceps) / lifter)\n",
    "    return np.multiply(mfcc, np.tile(cepwin, nframes).reshape((nframes,nceps)))\n",
    "\n",
    "\n",
    "def hz2mel(f):\n",
    "    \"\"\"Convert an array of frequency in Hz into mel.\"\"\"\n",
    "    return 1127.01048 * np.log(f/700 +1)\n",
    "\n",
    "\n",
    "def trfbank(fs, nfft, lowfreq=133.33, linsc=200/3., logsc=1.0711703, nlinfilt=13, nlogfilt=27, equalareas=False):\n",
    "    \"\"\"Compute triangular filterbank for MFCC computation.\n",
    "\n",
    "    Inputs:\n",
    "    fs:         sampling frequency (rate)\n",
    "    nfft:       length of the fft\n",
    "    lowfreq:    frequency of the lowest filter\n",
    "    linsc:      scale for the linear filters\n",
    "    logsc:      scale for the logaritmic filters\n",
    "    nlinfilt:   number of linear filters\n",
    "    nlogfilt:   number of log filters\n",
    "\n",
    "    Outputs:\n",
    "    res:  array with shape [N, nfft], with filter amplitudes for each column.\n",
    "            (N=nlinfilt+nlogfilt)\n",
    "    From scikits.talkbox\"\"\"\n",
    "    # Total number of filters\n",
    "    nfilt = nlinfilt + nlogfilt\n",
    "\n",
    "    #------------------------\n",
    "    # Compute the filter bank\n",
    "    #------------------------\n",
    "    # Compute start/middle/end points of the triangular filters in spectral\n",
    "    # domain\n",
    "    freqs = np.zeros(nfilt+2)\n",
    "    freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\n",
    "    freqs[nlinfilt:] = freqs[nlinfilt-1] * logsc ** np.arange(1, nlogfilt + 3)\n",
    "    if equalareas:\n",
    "        heights = np.ones(nfilt)\n",
    "    else:\n",
    "        heights = 2./(freqs[2:] - freqs[0:-2])\n",
    "\n",
    "    # Compute filterbank coeff (in fft domain, in bins)\n",
    "    fbank = np.zeros((nfilt, nfft))\n",
    "    # FFT bins (in Hz)\n",
    "    nfreqs = np.arange(nfft) / (1. * nfft) * fs\n",
    "    for i in range(nfilt):\n",
    "        low = freqs[i]\n",
    "        cen = freqs[i+1]\n",
    "        hi = freqs[i+2]\n",
    "\n",
    "        lid = np.arange(np.floor(low * nfft / fs) + 1,\n",
    "                        np.floor(cen * nfft / fs) + 1, dtype=np.int)\n",
    "        lslope = heights[i] / (cen - low)\n",
    "        rid = np.arange(np.floor(cen * nfft / fs) + 1,\n",
    "                        np.floor(hi * nfft / fs) + 1, dtype=np.int)\n",
    "        rslope = heights[i] / (hi - cen)\n",
    "        fbank[i][lid] = lslope * (nfreqs[lid] - low)\n",
    "        fbank[i][rid] = rslope * (hi - nfreqs[rid])\n",
    "\n",
    "    return fbank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "z0wCBUiXM9K7"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# lab1_proto.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter, hamming\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "\n",
    "\n",
    "# Function given by the exercise ----------------------------------\n",
    "\n",
    "def mspec(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, samplingrate=20000):\n",
    "    \"\"\"Computes Mel Filterbank features.\n",
    "\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        samplingrate: sampling rate of the original signal\n",
    "\n",
    "    Returns:\n",
    "        N x nfilters array with mel filterbank features (see trfbank for nfilters)\n",
    "    \"\"\"\n",
    "    frames = enframe(samples, winlen, winshift)\n",
    "    preemph = preemp(frames, preempcoeff)\n",
    "    windowed = windowing(preemph)\n",
    "    spec = powerSpectrum(windowed, nfft)\n",
    "    return logMelSpectrum(spec, samplingrate)\n",
    "\n",
    "\n",
    "def mfcc(samples, winlen = 400, winshift = 200, preempcoeff=0.97, nfft=512, nceps=13, samplingrate=20000, liftercoeff=22):\n",
    "    \"\"\"Computes Mel Frequency Cepstrum Coefficients.\n",
    "\n",
    "    Args:\n",
    "        samples: array of speech samples with shape (N,)\n",
    "        winlen: lenght of the analysis window\n",
    "        winshift: number of samples to shift the analysis window at every time step\n",
    "        preempcoeff: pre-emphasis coefficient\n",
    "        nfft: length of the Fast Fourier Transform (power of 2, >= winlen)\n",
    "        nceps: number of cepstrum coefficients to compute\n",
    "        samplingrate: sampling rate of the original signal\n",
    "        liftercoeff: liftering coefficient used to equalise scale of MFCCs\n",
    "\n",
    "    Returns:\n",
    "        N x nceps array with lifetered MFCC coefficients\n",
    "    \"\"\"\n",
    "    mspecs = mspec(samples, winlen, winshift, preempcoeff, nfft, samplingrate)\n",
    "    ceps = cepstrum(mspecs, nceps)\n",
    "    return lifter(ceps, liftercoeff)\n",
    "\n",
    "\n",
    "# Functions to be implemented ----------------------------------\n",
    "\n",
    "def enframe(samples, winlen, winshift):\n",
    "    \"\"\"\n",
    "    Slices the input samples into overlapping windows.\n",
    "\n",
    "    Args:\n",
    "        winlen: window length in samples.\n",
    "        winshift: shift of consecutive windows in samples\n",
    "    Returns:\n",
    "        numpy array [N x winlen], where N is the number of windows that fit\n",
    "        in the input signal\n",
    "    \"\"\"\n",
    "    if len(samples) < winlen:\n",
    "        raise ValueError('Too long winlen wrt input signal.')\n",
    "\n",
    "    N = 1 + int((len(samples) - winlen) / winshift)     # first window + how many times the window can be shifted\n",
    "    frames = np.zeros((N, winlen))\n",
    "\n",
    "    # init window\n",
    "    start = 0\n",
    "    end = start + winlen\n",
    "\n",
    "    for i in range(N):\n",
    "        # save frame\n",
    "        frames[i] = samples[start:end]\n",
    "\n",
    "        # shift window\n",
    "        start = start + winshift\n",
    "        end = start + winlen\n",
    "    return frames\n",
    "\n",
    "\n",
    "def preemp(input, p=0.97):\n",
    "    \"\"\"\n",
    "    Pre-emphasis filter.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech frames [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        p: preemhasis factor (defaults to the value specified in the exercise)\n",
    "\n",
    "    Output:\n",
    "        output: array of pre-emphasised speech samples\n",
    "    Note (you can use the function lfilter from scipy.signal)\n",
    "    \"\"\"\n",
    "    # y[n] = x[n] - p*x[n-1]\n",
    "    num = [1, -p]\n",
    "    den = [1]\n",
    "    return lfilter(num, den, input)\n",
    "\n",
    "\n",
    "def windowing(input):\n",
    "    \"\"\"\n",
    "    Applies hamming window to the input frames.\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "    Output:\n",
    "        array of windowed speech samples [N x M]\n",
    "    Note (you can use the function hamming from scipy.signal, include the sym=False option\n",
    "    if you want to get the same results as in the example)\n",
    "    \"\"\"\n",
    "    w = hamming(input.shape[1], sym=False)\n",
    "\n",
    "    # window shape (for explanation)\n",
    "    # plt.figure()\n",
    "    # plt.plot(w)\n",
    "    # plt.title('Hamming window')\n",
    "    # plt.xlabel('sample')\n",
    "    # plt.ylabel('amplitude')\n",
    "    # plt.show()\n",
    "\n",
    "    return input * w\n",
    "\n",
    "\n",
    "def powerSpectrum(input, nfft):\n",
    "    \"\"\"\n",
    "    Calculates the power spectrum of the input signal, that is the square of the modulus of the FFT\n",
    "\n",
    "    Args:\n",
    "        input: array of speech samples [N x M] where N is the number of frames and\n",
    "               M the samples per frame\n",
    "        nfft: length of the FFT\n",
    "    Output:\n",
    "        array of power spectra [N x nfft]\n",
    "    Note: you can use the function fft from scipy.fftpack\n",
    "    \"\"\"\n",
    "    return np.absolute(fft(input, n=nfft)) ** 2\n",
    "\n",
    "\n",
    "def logMelSpectrum(input, samplingrate):\n",
    "    \"\"\"\n",
    "    Calculates the log output of a Mel filterbank when the input is the power spectrum\n",
    "\n",
    "    Args:\n",
    "        input: array of power spectrum coefficients [N x nfft] where N is the number of frames and\n",
    "               nfft the length of each spectrum\n",
    "        samplingrate: sampling rate of the original signal (used to calculate the filterbank shapes)\n",
    "    Output:\n",
    "        array of Mel filterbank log outputs [N x nmelfilters] where nmelfilters is the number\n",
    "        of filters in the filterbank\n",
    "    Note: use the trfbank function provided in lab1_tools.py to calculate the filterbank shapes and\n",
    "          nmelfilters\n",
    "    \"\"\"\n",
    "    nfft = input.shape[1]\n",
    "    filterbank = trfbank(samplingrate, nfft)\n",
    "\n",
    "    # filters (for explanation)\n",
    "    # plt.figure()\n",
    "    # plt.plot(filterbank[::5])\n",
    "    # plt.title('Filterbank')\n",
    "    # plt.xlabel('frequency')\n",
    "    # plt.ylabel('amplitude')\n",
    "    # plt.show()\n",
    "\n",
    "    return np.log(input @ filterbank.T)\n",
    "\n",
    "\n",
    "def cepstrum(input, nceps):\n",
    "    \"\"\"\n",
    "    Calulates Cepstral coefficients from mel spectrum applying Discrete Cosine Transform\n",
    "\n",
    "    Args:\n",
    "        input: array of log outputs of Mel scale filterbank [N x nmelfilters] where N is the\n",
    "               number of frames and nmelfilters the length of the filterbank\n",
    "        nceps: number of output cepstral coefficients\n",
    "    Output:\n",
    "        array of Cepstral coefficients [N x nceps]\n",
    "    Note: you can use the function dct from scipy.fftpack.realtransforms\n",
    "    \"\"\"\n",
    "    cepstrum = dct(input)\n",
    "    cepstrum = cepstrum[:, :nceps]\n",
    "    return cepstrum\n",
    "\n",
    "\n",
    "def dtw(x, y, dist):\n",
    "    \"\"\"Dynamic Time Warping.\n",
    "\n",
    "    Args:\n",
    "        x, y: arrays of size NxD and MxD respectively, where D is the dimensionality\n",
    "              and N, M are the respective lenghts of the sequences\n",
    "        dist: distance function (can be used in the code as dist(x[i], y[j]))\n",
    "\n",
    "    Outputs:\n",
    "        d: global distance between the sequences (scalar) normalized to len(x)+len(y)\n",
    "        LD: local distance between frames from x and y (NxM matrix)\n",
    "        AD: accumulated distance between frames of x and y (NxM matrix)\n",
    "        path: best path through AD\n",
    "\n",
    "    Note that you only need to define the first output for this exercise.\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    M = y.shape[0]\n",
    "\n",
    "    # local distance between frames (frame-wise distance)\n",
    "    LD = np.zeros((N, M))\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            LD[i, j] = dist(x[i], y[j])\n",
    "\n",
    "    # accumulated distances\n",
    "    AD = np.zeros((N, M))\n",
    "    pred = np.zeros((N, M, 2), dtype='uint8')   # the predecessor is represented as tuple of coordinates\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            if i != 0 or j != 0:\n",
    "                # find minimum and save predecessor\n",
    "                candidates_pred = []\n",
    "                ad_candidates_pred = []\n",
    "                if i > 0:\n",
    "                    candidates_pred.append((i-1, j))\n",
    "                    ad_candidates_pred.append(AD[i-1, j])\n",
    "                if i > 0 and j > 0:\n",
    "                    candidates_pred.append((i-1, j-1))\n",
    "                    ad_candidates_pred.append(AD[i-1, j-1])\n",
    "                if j > 0:\n",
    "                    candidates_pred.append((i, j-1))\n",
    "                    ad_candidates_pred.append(AD[i, j-1])\n",
    "                m = min(ad_candidates_pred)\n",
    "                idx_candidate = ad_candidates_pred.index(m)\n",
    "                pred[i, j] = candidates_pred[idx_candidate]\n",
    "            else:\n",
    "                m = 0\n",
    "\n",
    "            # compute accumulated distance\n",
    "            AD[i, j] = LD[i, j] + m\n",
    "\n",
    "    # global distance\n",
    "    d = AD[-1, -1] / (N + M)\n",
    "\n",
    "    # best path (backtracking)\n",
    "    path = [(N-1, M-1)]\n",
    "    current = path[0]\n",
    "    while current != (0, 0):\n",
    "        path.insert(0, tuple(pred[current]))\n",
    "        current = path[0]\n",
    "\n",
    "    # show best path (debugging)\n",
    "    # LD_ = LD.copy()\n",
    "    # for node in path:\n",
    "    #     LD_[node] = 0   # to be visible in black\n",
    "    # plt.figure()\n",
    "    # plt.pcolormesh(LD_)\n",
    "    # plt.show()\n",
    "\n",
    "    return d, LD, AD, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "oSIlSSOCNFDh"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# lab2_tools.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def logsumexp(arr, axis=0):\n",
    "    \"\"\"Computes the sum of arr assuming arr is in the log domain.\n",
    "    Returns log(sum(exp(arr))) while minimizing the possibility of\n",
    "    over/underflow.\n",
    "    \"\"\"\n",
    "    arr = np.rollaxis(arr, axis)\n",
    "    # Use the max to normalize, as with the log this is what accumulates\n",
    "    # the less errors\n",
    "    vmax = arr.max(axis=0)\n",
    "    if vmax.ndim > 0:\n",
    "        vmax[~np.isfinite(vmax)] = 0\n",
    "    elif not np.isfinite(vmax):\n",
    "        vmax = 0\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        out = np.log(np.sum(np.exp(arr - vmax), axis=0))\n",
    "        out += vmax\n",
    "        return out\n",
    "\n",
    "\n",
    "def log_multivariate_normal_density_diag(X, means, covars):\n",
    "    \"\"\"Compute Gaussian log-density at X for a diagonal model\n",
    "\n",
    "    Args:\n",
    "        X: array like, shape (n_observations, n_features)\n",
    "        means: array like, shape (n_components, n_features)\n",
    "        covars: array like, shape (n_components, n_features)\n",
    "\n",
    "    Output:\n",
    "        lpr: array like, shape (n_observations, n_components)\n",
    "    From scikit-learn/sklearn/mixture/gmm.py\n",
    "    \"\"\"\n",
    "    n_samples, n_dim = X.shape\n",
    "    lpr = -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(covars), 1)\n",
    "                  + np.sum((means ** 2) / covars, 1)\n",
    "                  - 2 * np.dot(X, (means / covars).T)\n",
    "                  + np.dot(X ** 2, (1.0 / covars).T))\n",
    "    return lpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RZ_zVXtSNKFh"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# lab2_proto.py\n",
    "\n",
    "def concatTwoHMMs(hmm1, hmm2):\n",
    "    \"\"\" Concatenates 2 HMM models\n",
    "\n",
    "    Args:\n",
    "       hmm1, hmm2: two dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be different for each)\n",
    "\n",
    "    Output\n",
    "       dictionary with the same keys as the input but concatenated models:\n",
    "          startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "   \n",
    "    Example:\n",
    "       twoHMMs = concatHMMs(phoneHMMs['sil'], phoneHMMs['ow'])\n",
    "\n",
    "    See also: the concatenating_hmms.pdf document in the lab package\n",
    "    \"\"\"\n",
    "    M1 = len(hmm1['startprob']) - 1\n",
    "    M2 = len(hmm2['startprob']) - 1\n",
    "    K = M1 + M2\n",
    "\n",
    "    hmm_concat = {\n",
    "        'name': hmm1['name'] + hmm2['name'],\n",
    "        'startprob': np.zeros(K+1),\n",
    "        'transmat': np.zeros((K+1, K+1)),\n",
    "        'means': np.concatenate((hmm1['means'], hmm2['means'])),\n",
    "        'covars': np.concatenate((hmm1['covars'], hmm2['covars']))\n",
    "    }\n",
    "\n",
    "    hmm_concat['startprob'][:M1] = hmm1['startprob'][:-1]\n",
    "    hmm_concat['startprob'][M1:] = hmm1['startprob'][-1] * hmm2['startprob']\n",
    "\n",
    "    hmm_concat['transmat'][:M1, :M1] = hmm1['transmat'][:-1, :-1]\n",
    "    hmm_concat['transmat'][:M1, M1:] = hmm1['transmat'][:M1, -1].reshape(-1, 1) * hmm2['startprob'].reshape(1, -1)\n",
    "    hmm_concat['transmat'][M1:, M1:] = hmm2['transmat']\n",
    "\n",
    "    return hmm_concat\n",
    "\n",
    "\n",
    "# this is already implemented, but based on concat2HMMs() above\n",
    "def concatHMMs(hmmmodels, namelist):\n",
    "    \"\"\" Concatenates HMM models in a left to right manner\n",
    "\n",
    "    Args:\n",
    "       hmmmodels: dictionary of models indexed by model name. \n",
    "       hmmmodels[name] is a dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "       namelist: list of model names that we want to concatenate\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models:\n",
    "         startprob: K+1 array with priori probability of state\n",
    "          transmat: (K+1)x(K+1) transition matrix\n",
    "             means: KxD array of mean vectors\n",
    "            covars: KxD array of variances\n",
    "\n",
    "    K is the sum of the number of emitting states from the input models\n",
    "\n",
    "    Example:\n",
    "       wordHMMs['o'] = concatHMMs(phoneHMMs, ['sil', 'ow', 'sil'])\n",
    "    \"\"\"\n",
    "    concat = hmmmodels[namelist[0]]\n",
    "    for idx in range(1,len(namelist)):\n",
    "        concat = concatTwoHMMs(concat, hmmmodels[namelist[idx]])\n",
    "    return concat\n",
    "\n",
    "\n",
    "def gmmloglik(log_emlik, weights):\n",
    "    \"\"\"Log Likelihood for a GMM model based on Multivariate Normal Distribution.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: array like, shape (N, K).\n",
    "            contains the log likelihoods for each of N observations and\n",
    "            each of K distributions\n",
    "        weights:   weight vector for the K components in the mixture\n",
    "\n",
    "    Output:\n",
    "        gmmloglik: scalar, log likelihood of data given the GMM model.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def forward(log_emlik, log_startprob, log_transmat):\n",
    "    \"\"\"Forward (alpha) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: log transition probability from state i to j\n",
    "\n",
    "    Output:\n",
    "        forward_prob: NxM array of forward log probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "    log_alpha = np.zeros(log_emlik.shape)\n",
    "    log_startprob = log_startprob[:-1]      # remove non-emitting state\n",
    "    log_transmat = log_transmat[:-1, :-1]\n",
    "\n",
    "    log_alpha[0] = log_startprob + log_emlik[0]\n",
    "    for n in range(1, len(log_emlik)):\n",
    "        log_alpha[n] = logsumexp(log_alpha[n-1].reshape(-1, 1) + log_transmat) + log_emlik[n]\n",
    "\n",
    "    loglik = logsumexp(log_alpha[-1])\n",
    "    return log_alpha, loglik\n",
    "\n",
    "\n",
    "def backward(log_emlik, log_startprob, log_transmat):\n",
    "    \"\"\"Backward (beta) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: transition log probability from state i to j\n",
    "\n",
    "    Output:\n",
    "        backward_prob: NxM array of backward log probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "    log_beta = np.zeros(log_emlik.shape)\n",
    "    log_startprob = log_startprob[:-1]  # remove non-emitting state\n",
    "    log_transmat = log_transmat[:-1, :-1]\n",
    "\n",
    "    log_beta[-1] = 0\n",
    "    for n in range(len(log_emlik)-2, -1, -1):\n",
    "        log_beta[n] = logsumexp(log_transmat + log_emlik[n+1] + log_beta[n+1], axis=1)\n",
    "\n",
    "    loglik = logsumexp(log_emlik[0] + log_beta[0] + log_startprob)\n",
    "    return log_beta, loglik\n",
    "\n",
    "\n",
    "def viterbi(log_emlik, log_startprob, log_transmat, forceFinalState=True):\n",
    "    \"\"\"Viterbi path.\n",
    "\n",
    "    Args:\n",
    "        log_emlik: NxM array of emission log likelihoods, N frames, M states\n",
    "        log_startprob: log probability to start in state i\n",
    "        log_transmat: transition log probability from state i to j\n",
    "        forceFinalState: if True, start backtracking from the final state in\n",
    "                  the model, instead of the best state at the last time step\n",
    "\n",
    "    Output:\n",
    "        viterbi_loglik: log likelihood of the best path\n",
    "        viterbi_path: best path\n",
    "    \"\"\"\n",
    "    N, M = log_emlik.shape\n",
    "    logV = np.zeros((N, M))\n",
    "    B = np.zeros((N, M), dtype='uint32')    # the first row is not used but kept for simplicity\n",
    "    log_startprob = log_startprob[:-1]      # remove non-emitting state\n",
    "    log_transmat = log_transmat[:-1, :-1]\n",
    "\n",
    "    logV[0] = log_startprob + log_emlik[0]\n",
    "    for n in range(1, len(log_emlik)):\n",
    "        aux = logV[n - 1].reshape(-1, 1) + log_transmat\n",
    "        logV[n] = np.max(aux, axis=0) + log_emlik[n]\n",
    "        B[n] = np.argmax(aux, axis=0)\n",
    "    viterbi_loglik = np.max(logV[-1])\n",
    "\n",
    "    # backtracking\n",
    "    viterbi_path = np.zeros(N, dtype='uint32')\n",
    "    if forceFinalState:\n",
    "        viterbi_path[-1] = M-1\n",
    "    else:\n",
    "        viterbi_path[-1] = np.argmax(logV[-1])\n",
    "    for n in range(N-2, -1, -1):\n",
    "        viterbi_path[n] = B[n+1, viterbi_path[n+1]]\n",
    "\n",
    "    return viterbi_loglik, viterbi_path\n",
    "\n",
    "\n",
    "def statePosteriors(log_alpha, log_beta):\n",
    "    \"\"\"State posterior (gamma) probabilities in log domain.\n",
    "\n",
    "    Args:\n",
    "        log_alpha: NxM array of log forward (alpha) probabilities\n",
    "        log_beta: NxM array of log backward (beta) probabilities\n",
    "    where N is the number of frames, and M the number of states\n",
    "\n",
    "    Output:\n",
    "        log_gamma: NxM array of gamma probabilities for each of the M states in the model\n",
    "    \"\"\"\n",
    "    log_gamma = log_alpha + log_beta - logsumexp(log_alpha[-1])\n",
    "    return log_gamma\n",
    "\n",
    "\n",
    "def updateMeanAndVar(X, log_gamma, varianceFloor=5.0):\n",
    "    \"\"\" Update Gaussian parameters with diagonal covariance\n",
    "\n",
    "    Args:\n",
    "         X: NxD array of feature vectors\n",
    "         log_gamma: NxM state posterior probabilities in log domain\n",
    "         varianceFloor: minimum allowed variance scalar\n",
    "    were N is the lenght of the observation sequence, D is the\n",
    "    dimensionality of the feature vectors and M is the number of\n",
    "    states in the model\n",
    "\n",
    "    Outputs:\n",
    "         means: MxD mean vectors for each state\n",
    "         covars: MxD covariance (variance) vectors for each state\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    M = log_gamma.shape[1]\n",
    "    means = np.zeros((M, D))\n",
    "    covars = np.zeros((M, D))\n",
    "\n",
    "    for j in range(M):\n",
    "        means[j] = np.sum(np.exp(log_gamma[:, j]) * X.T, axis=1) / np.exp(logsumexp(log_gamma[:, j]))\n",
    "        covars[j] = np.sum(np.exp(log_gamma[:, j]) * (X - means[j]).T ** 2, axis=1) / np.exp(logsumexp(log_gamma[:, j]))\n",
    "        covars[covars < varianceFloor] = varianceFloor\n",
    "    return means, covars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "A5E0BNS5N4zG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pysndfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-29890504966c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpysndfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msndio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pysndfile'"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "\n",
    "# lab3_tools.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from pysndfile import sndio\n",
    "\n",
    "\n",
    "def path2info(path):\n",
    "    \"\"\"\n",
    "    path2info: parses paths in the TIDIGIT format and extracts information\n",
    "               about the speaker and the utterance\n",
    "\n",
    "    Example:\n",
    "    path2info('tidigits/disc_4.1.1/tidigits/train/man/ae/z9z6531a.wav')\n",
    "    \"\"\"\n",
    "    rest, filename = os.path.split(path)\n",
    "    rest, speakerID = os.path.split(rest)\n",
    "    rest, gender = os.path.split(rest)\n",
    "    digits = filename[:-5]\n",
    "    repetition = filename[-5]\n",
    "    return gender, speakerID, digits, repetition\n",
    "\n",
    "\n",
    "def loadAudio(filename):\n",
    "    \"\"\"\n",
    "    loadAudio: loads audio data from file using pysndfile\n",
    "\n",
    "    Note that, by default pysndfile converts the samples into floating point\n",
    "    numbers and rescales them in the range [-1, 1]. This is avoided by specifying\n",
    "    the option dtype=np.int16 which keeps both the original data type and range\n",
    "    of values.\n",
    "    \"\"\"\n",
    "    sndobj = sndio.read(filename, dtype=np.int16)\n",
    "    samplingrate = sndobj[1]\n",
    "    samples = np.array(sndobj[0])\n",
    "    return samples, samplingrate\n",
    "\n",
    "\n",
    "def frames2trans(sequence, outfilename=None, timestep=0.01):\n",
    "    \"\"\"\n",
    "    Outputs a standard transcription given a frame-by-frame\n",
    "    list of strings.\n",
    "\n",
    "    Example (using functions from Lab 1 and Lab 2):\n",
    "    phones = ['sil', 'sil', 'sil', 'ow', 'ow', 'ow', 'ow', 'ow', 'sil', 'sil']\n",
    "    trans = frames2trans(phones, 'oa.lab')\n",
    "\n",
    "    Then you can use, for example wavesurfer to open the wav file and the transcription\n",
    "    \"\"\"\n",
    "    sym = sequence[0]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    trans = ''\n",
    "    for t in range(len(sequence)):\n",
    "        if sequence[t] != sym:\n",
    "            trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "            sym = sequence[t]\n",
    "            start = end\n",
    "        end = end + timestep\n",
    "    trans = trans + str(start) + ' ' + str(end) + ' ' + sym + '\\n'\n",
    "    if outfilename != None:\n",
    "        with open(outfilename, 'w') as f:\n",
    "            f.write(trans)\n",
    "    return trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Q3VqpkH4N8XR"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "# lab3_proto\n",
    "\n",
    "def words2phones(wordList, pronDict, addSilence=True, addShortPause=True):\n",
    "    \"\"\" word2phones: converts word level to phone level transcription adding silence\n",
    "\n",
    "    Args:\n",
    "       wordList: list of word symbols\n",
    "       pronDict: pronunciation dictionary. The keys correspond to words in wordList\n",
    "       addSilence: if True, add initial and final silence\n",
    "       addShortPause: if True, add short pause model \"sp\" at end of each word\n",
    "    Output:\n",
    "       list of phone symbols\n",
    "    \"\"\"\n",
    "    phones = []\n",
    "\n",
    "    for word in wordList:\n",
    "        phones.extend(pronDict[word])       # insert phones of words\n",
    "        if addShortPause:\n",
    "            phones.append('sp')             # add short pause between words\n",
    "\n",
    "    if addSilence:\n",
    "        phones.insert(0, 'sil')             # add initial silence\n",
    "        phones.append('sil')                # add final silence\n",
    "\n",
    "    return phones\n",
    "\n",
    "def forcedAlignment(lmfcc, phoneHMMs, phoneTrans):\n",
    "    \"\"\" forcedAlignmen: aligns a phonetic transcription at the state level\n",
    "\n",
    "    Args:\n",
    "       lmfcc: NxD array of MFCC feature vectors (N vectors of dimension D)\n",
    "              computed the same way as for the training of phoneHMMs\n",
    "       phoneHMMs: set of phonetic Gaussian HMM models\n",
    "       phoneTrans: list of phonetic symbols to be aligned including initial and\n",
    "                   final silence\n",
    "\n",
    "    Returns:\n",
    "       list of strings in the form phoneme_index specifying, for each time step\n",
    "       the state from phoneHMMs corresponding to the viterbi path.\n",
    "    \"\"\"\n",
    "    # phone transcription => state transcription\n",
    "    phones = sorted(phoneHMMs.keys())\n",
    "    nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "    stateTrans = [p + '_' + str(i) for p in phoneTrans for i in range(nstates[p])]\n",
    "\n",
    "    # combined HMM for utterance\n",
    "    utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "\n",
    "    # Viterbi decoder\n",
    "    obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])\n",
    "    viterbiPath = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat']))[1]\n",
    "\n",
    "    # time alignment (frame-by-frame state transcription)\n",
    "    viterbiStateTrans = [stateTrans[s] for s in viterbiPath]\n",
    "\n",
    "    return viterbiStateTrans\n",
    "\n",
    "def hmmLoop(hmmmodels, namelist=None):\n",
    "    \"\"\" Combines HMM models in a loop\n",
    "\n",
    "    Args:\n",
    "       hmmmodels: list of dictionaries with the following keys:\n",
    "           name: phonetic or word symbol corresponding to the model\n",
    "           startprob: M+1 array with priori probability of state\n",
    "           transmat: (M+1)x(M+1) transition matrix\n",
    "           means: MxD array of mean vectors\n",
    "           covars: MxD array of variances\n",
    "       namelist: list of model names that we want to combine, if None,\n",
    "                 all the models in hmmmodels are used\n",
    "\n",
    "    D is the dimension of the feature vectors\n",
    "    M is the number of emitting states in each HMM model (could be\n",
    "      different in each model)\n",
    "\n",
    "    Output\n",
    "       combinedhmm: dictionary with the same keys as the input but\n",
    "                    combined models\n",
    "       stateMap: map between states in combinedhmm and states in the\n",
    "                 input models.\n",
    "\n",
    "    Examples:\n",
    "       phoneLoop = hmmLoop(phoneHMMs)\n",
    "       wordLoop = hmmLoop(wordHMMs, ['o', 'z', '1', '2', '3'])\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "LGmqW86RXLVv"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pcolormesh(matrix, title, ylabel):\n",
    "    plt.pcolormesh(matrix.T)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('time step')\n",
    "    plt.yticks(np.arange(matrix.shape[1]) + .5, range(matrix.shape[1]))\n",
    "    plt.xticks(np.arange(0, matrix.shape[0], 10) + .5, range(0, matrix.shape[0], 10))\n",
    "\n",
    "prondict = {\n",
    "    'o': ['ow'],\n",
    "    'z': ['z', 'iy', 'r', 'ow'],\n",
    "    '1': ['w', 'ah', 'n'],\n",
    "    '2': ['t', 'uw'],\n",
    "    '3': ['th', 'r', 'iy'],\n",
    "    '4': ['f', 'ao', 'r'],\n",
    "    '5': ['f', 'ay', 'v'],\n",
    "    '6': ['s', 'ih', 'k', 's'],\n",
    "    '7': ['s', 'eh', 'v', 'ah', 'n'],\n",
    "    '8': ['ey', 't'],\n",
    "    '9': ['n', 'ay', 'n'],\n",
    "}\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "np.random.seed(1)\n",
    "\n",
    "###############################\n",
    "# 4.1 Target class definition #\n",
    "###############################\n",
    "\n",
    "# unique states (=> classes for DNN)\n",
    "phoneHMMs = np.load('data/lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [p + '_' + str(i) for p in phones for i in range(nstates[p])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AGx9OW6lEv0i",
    "outputId": "31c53858-ebc7-497c-a762-0591f41d55d6"
   },
   "outputs": [],
   "source": [
    "#@title Debugging of forced alignment\n",
    "\n",
    "########################\n",
    "# 4.2 Forced alignment #\n",
    "########################\n",
    "\n",
    "# load correct example\n",
    "example = np.load('data/lab3_example.npz', allow_pickle=True)['example'].item()\n",
    "\n",
    "# feature extraction\n",
    "filename = 'data/tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)\n",
    "\n",
    "# transcription\n",
    "wordTrans = list(path2info(filename)[2])            # word transcription (contained in the filename)\n",
    "phoneTrans = words2phones(wordTrans, prondict)      # word transcription => phone transcription\n",
    "stateTrans = [p + '_' + str(i) for p in phoneTrans\n",
    "              for i in range(nstates[p])]           # phone transcription => state transcription\n",
    "\n",
    "# combined HMM for utterance\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)\n",
    "\n",
    "# Viterbi decoder\n",
    "obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])\n",
    "viterbiLoglik, viterbiPath = viterbi(obsloglik, np.log(utteranceHMM['startprob']), np.log(utteranceHMM['transmat']))\n",
    "\n",
    "# time alignment (frame-by-frame state transcription)\n",
    "viterbiStateTrans = [stateTrans[s] for s in viterbiPath]\n",
    "\n",
    "# save in standard format (to use it, put it in the same directory of .wav and open .wav with wavesurfer)\n",
    "frames2trans(viterbiStateTrans, outfilename='z43a.lab')\n",
    "\n",
    "# check results\n",
    "plt.figure()\n",
    "pcolormesh(lmfcc, 'MFCC - computed', ylabel='MFCC')\n",
    "plt.figure()\n",
    "pcolormesh(example['lmfcc'], 'MFCC - example', ylabel='MFCC')\n",
    "\n",
    "plt.figure()\n",
    "pcolormesh(obsloglik, 'Emission probabilities - computed', ylabel='state')\n",
    "plt.figure()\n",
    "pcolormesh(example['obsloglik'], 'Emission probabilities - example', ylabel='state')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(viterbiPath)) + .5, example['viterbiPath'] + .5, 'k', linewidth=2, label='example')\n",
    "plt.plot(np.arange(len(viterbiPath)) + .5, viterbiPath + .5, 'r--', linewidth=1, label='computed')\n",
    "plt.legend()\n",
    "plt.title('Viterbi path')\n",
    "plt.show()\n",
    "\n",
    "print('Word transcription, computed:', wordTrans)\n",
    "print('Word transcription, example:', example['wordTrans'])\n",
    "print()\n",
    "\n",
    "print('Phone transcription, computed:', phoneTrans)\n",
    "print('Phone transcription, example:', example['phoneTrans'])\n",
    "print()\n",
    "\n",
    "print('State transcription, computed:', stateTrans)\n",
    "print('State transcription, example:', example['stateTrans'])\n",
    "print()\n",
    "\n",
    "print('Viterbi log-likelihood, computed:', viterbiLoglik)\n",
    "print('Viterbi log-likelihood, example:', example['viterbiLoglik'])\n",
    "print()\n",
    "\n",
    "print('Forced alignment, computed:', viterbiStateTrans)\n",
    "print('Forced alignment, example:', example['viterbiStateTrans'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "wn0zwatj7vk1",
    "outputId": "ea349cbe-5449-42ab-c4cc-7f5c5cd58021"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "##########################\n",
    "# 4.3 Feature extraction #\n",
    "##########################\n",
    "\n",
    "def extract_feature(path, states):\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                filename = os.path.join(root, file)\n",
    "                samples, samplingrate = loadAudio(filename)\n",
    "                print(filename + '... ', end='')\n",
    "\n",
    "                # feature extraction (=> inputs for DNN)\n",
    "                lmfcc = mfcc(samples)\n",
    "                mspec_ = mspec(samples)\n",
    "\n",
    "                # forced alignment (=> targets for DNN)\n",
    "                wordTrans = list(path2info(filename)[2])                # word transcription (contained in the filename)\n",
    "                phoneTrans = words2phones(wordTrans, prondict)          # word transcription => phone transcription\n",
    "                targets = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n",
    "                targets = np.array([states.index(t) for t in targets])  # save targets as indeces\n",
    "\n",
    "                data.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec_, 'targets': targets})\n",
    "                print('done')\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "# training set\n",
    "filename = 'data/traindata.npz'\n",
    "if os.path.isfile(filename):\n",
    "    print('loading training set... ', end='')\n",
    "    traindata = np.load(filename, allow_pickle=True)['traindata']\n",
    "    print('done')\n",
    "else:\n",
    "    traindata = extract_feature('data/tidigits/disc_4.1.1/tidigits/train', stateList)\n",
    "    np.savez(filename, traindata=traindata)\n",
    "\n",
    "# test set\n",
    "filename = 'data/testdata.npz'\n",
    "if os.path.isfile(filename):\n",
    "    print('loading test set... ', end='')\n",
    "    testdata = np.load(filename, allow_pickle=True)['testdata']\n",
    "    print('done')\n",
    "else:\n",
    "    testdata = extract_feature('data/tidigits/disc_4.2.1/tidigits/test', stateList)\n",
    "    np.savez(filename, testdata=testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S-y_LN-ngg7A",
    "outputId": "8bd46eea-f239-4a49-feed-5e3fe6694a3d"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "import random\n",
    "\n",
    "####################################\n",
    "# 4.4 Training and validation sets #\n",
    "####################################\n",
    "\n",
    "def split_data_gender(data, percentage):\n",
    "    n = len(data)\n",
    "    speakers = list({path2info(u['filename'])[1] for u in data})    # set => no duplicates!\n",
    "    random.shuffle(speakers)                                        # shuffle to randomly select speakers\n",
    "    val_data = []\n",
    "\n",
    "    # add to validation set (all utterances of) speakers until the percentage is reached\n",
    "    for s in speakers:\n",
    "        speaker_data = [u for u in data if path2info(u['filename'])[1] == s]\n",
    "        val_data.extend(speaker_data)\n",
    "\n",
    "        # check if percentage is reached\n",
    "        if len(val_data) > percentage * n:\n",
    "            break\n",
    "\n",
    "    # add rest to training set\n",
    "    train_data = [u for u in data if u not in val_data]\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def split_data(data, percentage):\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "\n",
    "    # stratified sampling:\n",
    "    # 1. split data by gender\n",
    "    # 2. sample from these partitions preserving the distribution\n",
    "\n",
    "    # split data by gender\n",
    "    men_data = [u for u in data if path2info(u['filename'])[0] == 'man']\n",
    "    women_data = [u for u in data if path2info(u['filename'])[0] == 'woman']\n",
    "\n",
    "    # add utterances of men\n",
    "    train_data_, val_data_ = split_data_gender(men_data, percentage)\n",
    "    train_data.extend(train_data_)\n",
    "    val_data.extend(val_data_)\n",
    "\n",
    "    # add utterances of women\n",
    "    train_data_, val_data_ = split_data_gender(women_data, percentage)\n",
    "    train_data.extend(train_data_)\n",
    "    val_data.extend(val_data_)\n",
    "\n",
    "    return np.array(train_data), np.array(val_data)\n",
    "\n",
    "\n",
    "print('extracting validation set... ', end='')\n",
    "traindata, valdata = split_data(traindata, .1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "35ScaoQjcWQH"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "###########################################\n",
    "# 4.5 Acoustic context (dynamic features) #\n",
    "###########################################\n",
    "\n",
    "def stack_acoustic_context(features):\n",
    "    length = np.shape(features)[0]\n",
    "    idx_list = list(range(length))\n",
    "    idx_list = idx_list[1:4][::-1] + idx_list + idx_list[-4:-1][::-1]\n",
    "    output = [features[idx_list[i:i + 7]].reshape(-1) for i in range(length)]\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZwAS4gH78EoH",
    "outputId": "93583afd-ba41-4ad7-c8a4-296510c5bf32"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "###############################\n",
    "# 4.6 Feature standardisation #\n",
    "###############################\n",
    "\n",
    "def prepare_matrices(data, K, feature_type, dynamic_features, scaler=None):\n",
    "    if feature_type != 'lmfcc' and feature_type != 'mspec':\n",
    "        raise ValueError('Invalid feature type. Choose among lmfcc and mspec.')\n",
    "\n",
    "    N = sum([len(u['targets']) for u in data])      # total number of frames\n",
    "    D = data[0][feature_type].shape[1]\n",
    "    if dynamic_features:\n",
    "        D = D*7\n",
    "\n",
    "    x = np.zeros((N, D), dtype='float32')           # float32 to save memory\n",
    "    y = np.zeros(N)\n",
    "\n",
    "    # flatten (i.e. concatenate frames and targets of all utterances)\n",
    "    i = 0\n",
    "    for u in data:\n",
    "        n = len(u['targets'])                                       # number of frames for utterance\n",
    "        if dynamic_features:\n",
    "            u_features = stack_acoustic_context(u[feature_type])    # add dynamic features\n",
    "        else:\n",
    "            u_features = u[feature_type]\n",
    "\n",
    "        x[i:i+n] = u_features\n",
    "        y[i:i+n] = u['targets']\n",
    "        i += n\n",
    "\n",
    "    # standardise\n",
    "    if scaler is not None:\n",
    "        x = scaler.transform(x)\n",
    "\n",
    "    # one-hot encoding\n",
    "    y = to_categorical(y, K)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "feature_type = 'lmfcc'      # select here features to use\n",
    "dynamic_features = True     # select here whether to use dynamic features\n",
    "\n",
    "K = len(stateList)          # number of classes (don't touch)\n",
    "print('preparing matrices... ', end='')\n",
    "\n",
    "# matrices for training set\n",
    "train_x, train_y = prepare_matrices(traindata, K, feature_type, dynamic_features=dynamic_features)\n",
    "\n",
    "# standardisation of training set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "\n",
    "# matrices for validation and test sets (already standardised)\n",
    "val_x, val_y = prepare_matrices(valdata, K, feature_type, dynamic_features=dynamic_features, scaler=scaler)\n",
    "test_x, test_y = prepare_matrices(testdata, K, feature_type, dynamic_features=dynamic_features, scaler=scaler)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "uD6EEiIlcpyZ",
    "outputId": "1b52a360-9274-4b58-f71c-45c6f377c980"
   },
   "outputs": [],
   "source": [
    "#@title Training\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "####################################\n",
    "# 5. Phoneme recognition with DNNs #\n",
    "####################################\n",
    "\n",
    "model_dir = 'models'\n",
    "model_name = 'dnn_4hl_256u_dlmfcc_relu_bn'\n",
    "model_filepath = os.path.join(model_dir, model_name + '.h5')\n",
    "\n",
    "if not os.path.isfile(model_filepath):\n",
    "    # create directory to save model\n",
    "    try:\n",
    "        os.mkdir(model_dir)\n",
    "        print('Directory', model_dir, 'created')\n",
    "    except FileExistsError:\n",
    "        print('Directory', model_dir, 'already existing')\n",
    "\n",
    "    # architecture\n",
    "    dnn = Sequential()\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            dnn.add(Dense(units=256, input_shape=(train_x.shape[1],)))\n",
    "        else:\n",
    "            dnn.add(Dense(units=256))\n",
    "        dnn.add(BatchNormalization())\n",
    "        dnn.add(Activation(activation='relu'))\n",
    "    dnn.add(Dense(units=K, activation='softmax'))\n",
    "    dnn.summary()\n",
    "\n",
    "    # compile\n",
    "    dnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train\n",
    "    checkpoint = ModelCheckpoint(model_filepath, verbose=1, save_best_only=True)\n",
    "    history = dnn.fit(x=train_x, y=train_y, batch_size=256, epochs=10, validation_data=(val_x, val_y), callbacks=[checkpoint])\n",
    "\n",
    "    # plot loss\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.savefig(os.path.join(model_dir, model_name + '_loss.jpg'))\n",
    "\n",
    "    # plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='val')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "    plt.savefig(os.path.join(model_dir, model_name + '_accuracy.jpg'))\n",
    "\n",
    "# load (best checkpoint of) model\n",
    "print('loading best checkpoint... ', end='')\n",
    "dnn = load_model(model_filepath)\n",
    "print('done')\n",
    "dnn.summary()\n",
    "\n",
    "# evaluate on validation set (for model selection)\n",
    "metric_values = dnn.evaluate(x=val_x, y=val_y, batch_size=256)\n",
    "with open(os.path.join(model_dir, 'model_selection.txt'), 'a') as f:\n",
    "    f.write(model_name + '\\n')\n",
    "    for n, v in zip(dnn.metrics_names, metric_values):\n",
    "        print('validation {}: {}'.format(n, v))\n",
    "        f.write('validation {}: {}\\n'.format(n, v))\n",
    "    f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PVT53SmAqBO4",
    "outputId": "7b244656-f081-4b96-f1fc-3ee9e21cdeb2"
   },
   "outputs": [],
   "source": [
    "#@title Evaluation of best DNN\n",
    "!pip install edit_distance > /dev/null\n",
    "\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from edit_distance import SequenceMatcher\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "###########################\n",
    "# 5.1 Detailed evaluation #\n",
    "###########################\n",
    "\n",
    "def states2phones(y_states, phones, states):\n",
    "    # work in one-hot encoding\n",
    "    y_phones = np.zeros((y_states.shape[0], len(phones)))\n",
    "    y_states = to_categorical(y_states, len(states))\n",
    "\n",
    "    for i, p in enumerate(phones):\n",
    "        # indeces of states belonging to phoneme p\n",
    "        idx_states = [j for j in range(len(states)) if states[j].split(sep='_')[0] == p]\n",
    "\n",
    "        # merge states (just sum columns in one-hot encoding!)\n",
    "        y_phones[:, i] = np.sum(y_states[:, idx_states], axis=1)\n",
    "\n",
    "    # go back to labels\n",
    "    y_phones = np.argmax(y_phones, axis=1)\n",
    "\n",
    "    return y_phones\n",
    "\n",
    "\n",
    "def merge_consequent_states(y):\n",
    "    cur_y = y[0]\n",
    "    merged_y = [cur_y]\n",
    "    for i in y:\n",
    "        if i == cur_y:\n",
    "            continue\n",
    "        else:\n",
    "            cur_y = i\n",
    "            merged_y += [cur_y]\n",
    "    return merged_y\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.xlabel('predictions')\n",
    "    plt.ylabel('ground truth')\n",
    "\n",
    "\n",
    "# predict\n",
    "y_pred = np.argmax(dnn.predict(x=test_x, batch_size=256), axis=1)\n",
    "y_true = np.argmax(test_y, axis=1)\n",
    "accuracy = Accuracy()\n",
    "\n",
    "# frame-by-frame at the state level\n",
    "accuracy.update_state(y_true, y_pred)\n",
    "print('Frame-by-frame accuracy at the state level: {:.2f}%'.format(accuracy.result().numpy()*100))\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_true, y_pred)\n",
    "plt.title('Frame-by-frame confusion matrix at the state level')\n",
    "\n",
    "# frame-by-frame at the phoneme level\n",
    "y_pred_phones = states2phones(y_pred, phones, stateList)\n",
    "y_true_phones = states2phones(y_true, phones, stateList)\n",
    "accuracy.reset_states()\n",
    "accuracy.update_state(y_true_phones, y_pred_phones)\n",
    "print('Frame-by-frame accuracy at the phoneme level: {:.2f}%'.format(accuracy.result().numpy()*100))\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_true_phones, y_pred_phones)\n",
    "plt.title('Frame-by-frame confusion matrix at the phoneme level')\n",
    "\n",
    "# PER at the state level\n",
    "N = 10000     # number of frames to consider (distance computation is expensive)\n",
    "y_pred_merged = merge_consequent_states(y_pred[:N])\n",
    "y_true_merged = merge_consequent_states(y_true[:N])\n",
    "sm = SequenceMatcher(a=y_true_merged, b=y_pred_merged)\n",
    "edit_distance = sm.distance()\n",
    "print('PER at the state level: {:.2f}%'.format(edit_distance/N*100))\n",
    "\n",
    "# PER at the phoneme level\n",
    "y_pred_merged = merge_consequent_states(y_pred_phones[:N])\n",
    "y_true_merged = merge_consequent_states(y_true_phones[:N])\n",
    "sm = SequenceMatcher(a=y_true_merged, b=y_pred_merged)\n",
    "edit_distance = sm.distance()\n",
    "print('PER at the phoneme level: {:.2f}%'.format(edit_distance/N*100))\n",
    "\n",
    "# posteriors for first utterance\n",
    "utterance = testdata[0]\n",
    "x, y = prepare_matrices([utterance], K, feature_type, dynamic_features=dynamic_features, scaler=scaler)\n",
    "y_pred = dnn.predict(x=x, batch_size=256)\n",
    "wordTrans = path2info(utterance['filename'])[2]\n",
    "plt.figure()\n",
    "pcolormesh(y_pred, 'Predicted posteriors (produced by DNN) - words: ' + wordTrans, ylabel='state')\n",
    "plt.figure()\n",
    "pcolormesh(y, 'Target posteriors (produced by forced alignment) - words: ' + wordTrans, ylabel='state')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dt2119_lab3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
